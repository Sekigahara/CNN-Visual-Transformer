{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7abfab5-0254-41b3-b7f6-ebdf4ab6c1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:59:28.748964: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-14 11:59:28.775715: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-14 11:59:29.219808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:59:29.892880: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-14 11:59:29.940404: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-14 11:59:29.940450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32700357-4981-41bc-a57b-08d7ac74af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13bfee30-751d-401c-92ef-c3fde5e51e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ad31da-4dce-444d-8265-257cdc523ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the label into the categorical crossentropy\n",
    "\n",
    "y_train_categorical = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_categorical = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea496c7-dcca-4ad6-b05e-5bffc000674d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60632886-6dd3-4b59-b399-d0e2ef9a68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# ViT Base\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 10  # For real training, use num_epochs=100. 10 is a test value\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 12\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 12\n",
    "mlp_head_units = [\n",
    "    3072,\n",
    "]\n",
    "\n",
    "config_json = {   \n",
    "    \"learning_rate\" : learning_rate,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"num_epochs\" : num_epochs,\n",
    "    \"image_size\" : image_size,\n",
    "    \"patch_size\" : patch_size,\n",
    "    \"num_patches\" : num_patches,\n",
    "    \"projection_dim\" : projection_dim,\n",
    "    \"num_heads\" : num_heads,\n",
    "    \"final_dropout_layer\" : 0.5,\n",
    "    \"transformer_units\" : transformer_units,\n",
    "    \"transformer_layers\" : transformer_layers,\n",
    "    \"mlp_head_units\" : mlp_head_units\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9792c9b4-360e-436d-9b41-0b88ede9ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.vision_transformers.patches import Patches\n",
    "from modules.vision_transformers.patch_encoder import PatchEncoder, mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "770db177-7ca9-437c-8f72-13a802aa9cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:59:31.019051: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-14 11:59:31.019117: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-14 11:59:31.019142: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-14 11:59:31.113679: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-14 11:59:31.113724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-14 11:59:31.113730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-14 11:59:31.113755: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-14 11:59:31.113774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13689 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation for resize\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.Normalization(),\n",
    "    tf.keras.layers.Resizing(image_size, image_size),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(factor=0.02),\n",
    "    tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    #tf.keras.layers.RandomContrast(factor=0.1)\n",
    "])\n",
    "\n",
    "# Compute the average and variance of the training data for normalization purpose\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52fd947f-71f5-4762-bdeb-b98e05244c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def create_classifier():\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Apply augment resize\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    # Create Patches\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "\n",
    "    # Encode every patches position\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "        # Create multilayers about how many transformers layer needed\n",
    "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    \n",
    "        # Create a multi-head attention layer\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "\n",
    "        # Skip connection 1\n",
    "        x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "\n",
    "        # layer normalization 2\n",
    "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "\n",
    "        # NLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "\n",
    "        # Skip Connection\n",
    "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = tf.keras.layers.Flatten()(representation)\n",
    "    representation = tf.keras.layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = tf.keras.layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b227c8d3-bfff-4cb6-9d79-7401f5902167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8cf58b-c65b-4323-9cfe-f02a1d881346",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(x_train) * num_epochs\n",
    "decay_steps = total_steps * 0.4\n",
    "# Cosine Learning Rate Decay\n",
    "cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    alpha=0.1,\n",
    "    warmup_steps=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257de0c1-66f8-4333-b6cd-84aee4c6879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=cosine_decay_scheduler),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.TopKCategoricalAccuracy(3, name='top-3-accuracy')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e936761-77ff-499d-9d30-224d11972b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:59:58.519488: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 168ms/step - accuracy: 0.2666 - loss: 2.8001 - top-3-accuracy: 0.5810 - val_accuracy: 0.4498 - val_loss: 1.5154 - val_top-3-accuracy: 0.7813\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 170ms/step - accuracy: 0.4251 - loss: 1.5930 - top-3-accuracy: 0.7579 - val_accuracy: 0.5584 - val_loss: 1.2133 - val_top-3-accuracy: 0.8564\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 169ms/step - accuracy: 0.5342 - loss: 1.3082 - top-3-accuracy: 0.8328 - val_accuracy: 0.6179 - val_loss: 1.0674 - val_top-3-accuracy: 0.8871\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 168ms/step - accuracy: 0.5752 - loss: 1.1832 - top-3-accuracy: 0.8622 - val_accuracy: 0.6168 - val_loss: 1.0823 - val_top-3-accuracy: 0.8908\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 168ms/step - accuracy: 0.6150 - loss: 1.0866 - top-3-accuracy: 0.8843 - val_accuracy: 0.6648 - val_loss: 0.9340 - val_top-3-accuracy: 0.9168\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 168ms/step - accuracy: 0.6430 - loss: 1.0135 - top-3-accuracy: 0.8960 - val_accuracy: 0.6753 - val_loss: 0.9041 - val_top-3-accuracy: 0.9162\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 169ms/step - accuracy: 0.6610 - loss: 0.9634 - top-3-accuracy: 0.9057 - val_accuracy: 0.6885 - val_loss: 0.8633 - val_top-3-accuracy: 0.9254\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 168ms/step - accuracy: 0.6719 - loss: 0.9352 - top-3-accuracy: 0.9094 - val_accuracy: 0.6939 - val_loss: 0.8523 - val_top-3-accuracy: 0.9268\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 168ms/step - accuracy: 0.6844 - loss: 0.8907 - top-3-accuracy: 0.9177 - val_accuracy: 0.7090 - val_loss: 0.8253 - val_top-3-accuracy: 0.9319\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 168ms/step - accuracy: 0.6976 - loss: 0.8602 - top-3-accuracy: 0.9254 - val_accuracy: 0.7223 - val_loss: 0.7890 - val_top-3-accuracy: 0.9350\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train_categorical,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(x_test, y_test_categorical)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6eb25a-bf12-482a-9512-afa10afbbc85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481bdd50-6465-448d-a404-86e006492ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b873f10-8012-4b31-9ea9-2a0937787f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated = model.evaluate(x_test, y_test_categorical)\n",
    "final_acc, final_loss, final_top_3_acc = evaluated[0], evaluated[1], evaluated[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5015427-5161-4e7e-b225-526f09f3792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'model/model_base_vit_cifar10_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ece8e3-c3da-4769-b804-d44bf294bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Save Train result\n",
    "fig = plt.gcf()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d2b1b-36dc-4dcc-b601-65c040deb1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(save_name + \"_loss.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489c2f7-1420-4561-9477-871cf4d99496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Train result\n",
    "fig = plt.gcf()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31153cf7-cf90-41b2-87cf-206b1fb1a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(save_name + \"_accuracy.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f7782-2df4-43f1-96d6-652f82899b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('{}.keras'.format(save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20cd9b9-1281-44c0-a416-666e92b533ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config_json['final_accuracy'] = final_acc,\n",
    "config_json['final_loss'] = final_loss\n",
    "config_json['final_top_3_acc'] = final_top_3_acc\n",
    "with open('{}_config.json'.format(save_name), 'w') as f:\n",
    "    json.dump(config_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0382ea5-e34e-44df-a85d-4430160f0f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
